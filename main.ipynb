{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a690f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# ALL THE IMPROTS ###################\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers.reshaping.reshape import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12903802",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "############################## IMAGE GENERATOR #################################\n",
    "\n",
    "img_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9733e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 1 classes.\n",
      "Found 8000 images belonging to 1 classes.\n",
      "Found 2000 images belonging to 1 classes.\n",
      "Found 2000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "########################### FLOW FROM DIRECTORY#################################\n",
    "\n",
    "face_train = img_generator.flow_from_directory('data/train_images',target_size=(512,512),shuffle=False,\n",
    "                                               seed=40,save_format='jpg', batch_size=16, classes=None,\n",
    "                                               class_mode=None)\n",
    "\n",
    "comic_train = img_generator.flow_from_directory('data/train_cartoon',target_size=(512,512),shuffle=False,\n",
    "                                                seed=40,save_format='jpg',batch_size=16, classes=None,\n",
    "                                                class_mode=None)\n",
    "\n",
    "face_val = img_generator.flow_from_directory('data/val_images',target_size=(512,512),shuffle=False,\n",
    "                                             seed=40,save_format='jpg',batch_size=4,classes=None,\n",
    "                                             class_mode=None)\n",
    "\n",
    "comic_val = img_generator.flow_from_directory('data/val_cartoon',target_size=(512,512),shuffle=False,\n",
    "                                              seed=40,save_format='jpg',batch_size=4,classes=None,\n",
    "                                              class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422d7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=zip(face_train, comic_train)\n",
    "val_generator=zip(face_val, comic_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69cd9f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"real2comic\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 512, 512, 3)       84        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 32)      896       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 32)      9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 64, 64, 32)       9248      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 128, 128, 32)     9248      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 256, 256, 32)     9248      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 512, 512, 3)      867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,335\n",
      "Trainable params: 57,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#########################################################################\n",
    "model=Sequential(name=\"real2comic\")\n",
    "model.add(keras.Input(shape=(512,512,3)))\n",
    "model.add(layers.Conv2D(3,3,activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(32,3,activation='relu',strides=2, padding='same'))\n",
    "model.add(layers.Conv2D(32,3,activation='relu',strides=2, padding='same'))\n",
    "model.add(layers.Conv2D(32,3,activation='relu',strides=2, padding='same'))\n",
    "\n",
    "model.add(layers.Conv2D(32,3,activation='relu',padding='same'))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2DTranspose(32,3,activation='relu', padding='same'))\n",
    "model.add(layers.Conv2DTranspose(32,3,activation='relu', strides=2, padding='same'))\n",
    "model.add(layers.Conv2DTranspose(32,3,activation='relu', strides=2, padding='same'))\n",
    "model.add(layers.Conv2DTranspose(3,3, activation='sigmoid',strides=2, padding='same'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78249cb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 467s 925ms/step - loss: 0.1488 - accuracy: 0.5467 - val_loss: 0.1283 - val_accuracy: 0.6522\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 460s 920ms/step - loss: 0.1278 - accuracy: 0.6954 - val_loss: 0.1239 - val_accuracy: 0.7231\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1243 - accuracy: 0.7133 - val_loss: 0.1225 - val_accuracy: 0.7029\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1229 - accuracy: 0.7202 - val_loss: 0.1211 - val_accuracy: 0.7165\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1215 - accuracy: 0.7244 - val_loss: 0.1200 - val_accuracy: 0.7277\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1210 - accuracy: 0.7272 - val_loss: 0.1195 - val_accuracy: 0.7455\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1201 - accuracy: 0.7314 - val_loss: 0.1191 - val_accuracy: 0.7553\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 457s 915ms/step - loss: 0.1192 - accuracy: 0.7345 - val_loss: 0.1179 - val_accuracy: 0.7554\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1184 - accuracy: 0.7367 - val_loss: 0.1176 - val_accuracy: 0.7567\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1178 - accuracy: 0.7384 - val_loss: 0.1171 - val_accuracy: 0.7579\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1168 - accuracy: 0.7384 - val_loss: 0.1165 - val_accuracy: 0.7602\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1163 - accuracy: 0.7369 - val_loss: 0.1162 - val_accuracy: 0.7552\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1158 - accuracy: 0.7369 - val_loss: 0.1156 - val_accuracy: 0.7571\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 457s 915ms/step - loss: 0.1151 - accuracy: 0.7371 - val_loss: 0.1151 - val_accuracy: 0.7624\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1150 - accuracy: 0.7356 - val_loss: 0.1147 - val_accuracy: 0.7645\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 459s 919ms/step - loss: 0.1145 - accuracy: 0.7359 - val_loss: 0.1143 - val_accuracy: 0.7633\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1139 - accuracy: 0.7362 - val_loss: 0.1153 - val_accuracy: 0.7711\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1135 - accuracy: 0.7377 - val_loss: 0.1145 - val_accuracy: 0.7735\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 458s 916ms/step - loss: 0.1132 - accuracy: 0.7393 - val_loss: 0.1141 - val_accuracy: 0.7724\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 458s 917ms/step - loss: 0.1130 - accuracy: 0.7391 - val_loss: 0.1129 - val_accuracy: 0.7774\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 549s 1s/step - loss: 0.1128 - accuracy: 0.7392 - val_loss: 0.1125 - val_accuracy: 0.7766\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 578s 1s/step - loss: 0.1128 - accuracy: 0.7396 - val_loss: 0.1128 - val_accuracy: 0.7784\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 475s 951ms/step - loss: 0.1123 - accuracy: 0.7404 - val_loss: 0.1123 - val_accuracy: 0.7786\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 523s 1s/step - loss: 0.1122 - accuracy: 0.7403 - val_loss: 0.1124 - val_accuracy: 0.7783\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 501s 1s/step - loss: 0.1118 - accuracy: 0.7416 - val_loss: 0.1132 - val_accuracy: 0.7797\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 481s 963ms/step - loss: 0.1117 - accuracy: 0.7424 - val_loss: 0.1124 - val_accuracy: 0.7789\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 478s 957ms/step - loss: 0.1114 - accuracy: 0.7426 - val_loss: 0.1119 - val_accuracy: 0.7784\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 459s 918ms/step - loss: 0.1115 - accuracy: 0.7412 - val_loss: 0.1121 - val_accuracy: 0.7784\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 458s 917ms/step - loss: 0.1113 - accuracy: 0.7411 - val_loss: 0.1121 - val_accuracy: 0.7776\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 494s 989ms/step - loss: 0.1110 - accuracy: 0.7422 - val_loss: 0.1114 - val_accuracy: 0.7804\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 486s 973ms/step - loss: 0.1125 - accuracy: 0.7322 - val_loss: 0.1110 - val_accuracy: 0.7780\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 517s 1s/step - loss: 0.1107 - accuracy: 0.7414 - val_loss: 0.1109 - val_accuracy: 0.7801\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 464s 928ms/step - loss: 0.1109 - accuracy: 0.7416 - val_loss: 0.1115 - val_accuracy: 0.7746\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 456s 913ms/step - loss: 0.1105 - accuracy: 0.7414 - val_loss: 0.1111 - val_accuracy: 0.7809\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 456s 912ms/step - loss: 0.1103 - accuracy: 0.7423 - val_loss: 0.1109 - val_accuracy: 0.7794\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 456s 913ms/step - loss: 0.1101 - accuracy: 0.7429 - val_loss: 0.1107 - val_accuracy: 0.7771\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 457s 914ms/step - loss: 0.1100 - accuracy: 0.7434 - val_loss: 0.1107 - val_accuracy: 0.7765\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 482s 964ms/step - loss: 0.1099 - accuracy: 0.7437 - val_loss: 0.1116 - val_accuracy: 0.7762\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 494s 988ms/step - loss: 0.1102 - accuracy: 0.7430 - val_loss: 0.1106 - val_accuracy: 0.7753\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 485s 971ms/step - loss: 0.1097 - accuracy: 0.7446 - val_loss: 0.1101 - val_accuracy: 0.7740\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 464s 928ms/step - loss: 0.1096 - accuracy: 0.7442 - val_loss: 0.1101 - val_accuracy: 0.7731\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 464s 929ms/step - loss: 0.1094 - accuracy: 0.7447 - val_loss: 0.1098 - val_accuracy: 0.7686\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 493s 987ms/step - loss: 0.1096 - accuracy: 0.7441 - val_loss: 0.1098 - val_accuracy: 0.7751\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 498s 996ms/step - loss: 0.1095 - accuracy: 0.7440 - val_loss: 0.1099 - val_accuracy: 0.7775\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 508s 1s/step - loss: 0.1092 - accuracy: 0.7452 - val_loss: 0.1097 - val_accuracy: 0.7720\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 485s 971ms/step - loss: 0.1094 - accuracy: 0.7443 - val_loss: 0.1098 - val_accuracy: 0.7732\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 458s 915ms/step - loss: 0.1091 - accuracy: 0.7449 - val_loss: 0.1095 - val_accuracy: 0.7716\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 461s 922ms/step - loss: 0.1089 - accuracy: 0.7451 - val_loss: 0.1095 - val_accuracy: 0.7692\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 459s 918ms/step - loss: 0.1089 - accuracy: 0.7451 - val_loss: 0.1094 - val_accuracy: 0.7682\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.7456"
     ]
    }
   ],
   "source": [
    "model.fit(x=train_generator, validation_data = val_generator, steps_per_epoch=500,\n",
    "          validation_steps=500, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelV5.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
